{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-22T01:14:26.345022Z",
     "end_time": "2023-04-22T01:14:26.527559Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#DEATHES\n",
    "df = pd.read_csv('../dataset/annual_deaths_by_causes.csv')\n",
    "\n",
    "#Cleaning from extra spaces in columns and data Replace NaN with 0\n",
    "df.columns = df.columns.str.strip()\n",
    "df = df.apply(lambda x:x.str.strip() if x.dtype == \"object\" else x)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "#delete extra columns\n",
    "df.drop('code',axis=1, inplace=True)\n",
    "\n",
    "#add column sum of deaths\n",
    "df['total'] = df.iloc[:,2:].sum(axis=1)\n",
    "\n",
    "# Write the modified DataFrame to a new CSV file\n",
    "df.to_csv('C:/ProgramData/MySQL/MySQL Server 8.0/Uploads/cleaned-dataset/deaths1990-2019.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "#SUICIDES\n",
    "df = pd.read_csv('../dataset/suicide rates1985-2016.csv')\n",
    "\n",
    "#Cleaning from extra spaces in columns and data Replace NaN with 0\n",
    "df.columns = df.columns.str.strip()\n",
    "df = df.apply(lambda x:x.str.strip() if x.dtype == \"object\" else x)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# group by 'country', 'year', 'gdp_per_capita' columns and aggregate 'suicides_no' and 'population' columns\n",
    "df = df.groupby(['country','year','gdp_per_capita ($)'], as_index=False).agg({'suicides_no': 'sum', 'population': 'sum'})\n",
    "#after this you do not have to delete extra columns!\n",
    "\n",
    "df.to_csv('C:/ProgramData/MySQL/MySQL Server 8.0/Uploads/cleaned-dataset/suicides1985-2016GROUPED.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-22T01:14:26.531550Z",
     "end_time": "2023-04-22T01:14:26.636466Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "#HAPPINESS\n",
    "# Read the CSV file with ';' delimiter\n",
    "df = pd.read_csv('../dataset/world-happiness-report-2005-2018.csv', sep=';')\n",
    "\n",
    "#Cleaning from extra spaces in columns and data Replace NaN with 0\n",
    "df.columns = df.columns.str.strip()\n",
    "df = df.apply(lambda x:x.str.strip() if x.dtype == \"object\" else x)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "#delete extra column\n",
    "df.drop('Year',axis=1, inplace=True)\n",
    "\n",
    "#making the same name of the same countries\n",
    "stand_name = {\n",
    "    'Congo (Brazzaville)':'Congo',\n",
    "    'Congo (Kinshasa)':'Congo'\n",
    "}\n",
    "df['Country name'] = df['Country name'].replace(stand_name)\n",
    "\n",
    "#group by country name and find average of other data of different years\n",
    "df = df.groupby(['Country name'],as_index=False).mean()\n",
    "\n",
    "# Save the file with ',' delimiter\n",
    "df.to_csv('C:/ProgramData/MySQL/MySQL Server 8.0/Uploads/cleaned-dataset/happiness.csv', sep=',', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-22T01:14:26.641455Z",
     "end_time": "2023-04-22T01:14:26.670523Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "#COUNTRIES\n",
    "df = pd.read_csv('../dataset/countries of the world.csv')\n",
    "\n",
    "#Cleaning from extra spaces in columns and data Replace NaN with 0\n",
    "df.columns = df.columns.str.strip()\n",
    "df = df.apply(lambda x:x.str.strip() if x.dtype == \"object\" else x)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# replace commas with periods in the numeric columns\n",
    "df = df.replace(',', '.', regex=True)\n",
    "\n",
    "mapping = {\n",
    "    'ASIA (EX. NEAR EAST)': 'ASIA',\n",
    "    'EASTERN EUROPE': 'EUROPE',\n",
    "    'NORTHERN AFRICA': 'AFRICA',\n",
    "    'WESTERN EUROPE': 'EUROPE',\n",
    "    'SUB-SAHARAN AFRICA': 'AFRICA',\n",
    "    'LATIN AMER. & CARIB': 'LATIN AMERICA',\n",
    "    'C.W. OF IND. STATES': 'ASIA',\n",
    "    'NEAR EAST': 'ASIA',\n",
    "    'BALTICS': 'EUROPE'\n",
    "}\n",
    "df['Region'] = df['Region'].replace(mapping)\n",
    "\n",
    "df.to_csv('C:/ProgramData/MySQL/MySQL Server 8.0/Uploads/cleaned-dataset/countries.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-22T01:14:26.673517Z",
     "end_time": "2023-04-22T01:14:26.702681Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
